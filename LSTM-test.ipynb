{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling LSTM, GRADIENT BOOSTING, FAST TEXT + RFC, FAST TEXT + LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImportS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import spacy\n",
    "import joblib\n",
    "\n",
    "from collections import defaultdict\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.models import model_from_json\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/undersampled_data_60_40.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NaNs from df['stopwords_punct_lemma']\n",
    "df.dropna(subset=['stopwords_punct_lemma'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Balanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model architecture from JSON file\n",
    "json_file_path = 'data/model5.json' \n",
    "json_file = open(json_file_path, 'r')\n",
    "loaded_model_json = json_file.read()\n",
    "json_file.close()\n",
    "loaded_model = model_from_json(loaded_model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model weights\n",
    "weights_file_path = 'data/model_weights5.h5'\n",
    "loaded_model.load_weights(weights_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer for preprocessing\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer_path = 'data/tokenizer.pkl' \n",
    "with open(tokenizer_path, 'rb') as handle:\n",
    "    tokenizer = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toxicity prediction balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 43ms/step\n",
      "Toxicity prediction: 1.0\n"
     ]
    }
   ],
   "source": [
    "input_text = \"Trump is not like gay people, fancy blonde hair\"\n",
    "# Preprocess the input text\n",
    "sequence = tokenizer.texts_to_sequences([input_text])\n",
    "max_sequence_length = 100  # Adjust this based on your model's input shape\n",
    "padded_sequence = pad_sequences(sequence, maxlen=max_sequence_length)\n",
    "toxicity_prediction = loaded_model.predict(padded_sequence)\n",
    "toxicity_prediction_rounded = round(float(toxicity_prediction), 4)\n",
    "print(\"Toxicity prediction:\", toxicity_prediction_rounded)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cleaned balanced data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model architecture from JSON file\n",
    "json_file_path1 = 'data/model_clean.json' \n",
    "json_file1 = open(json_file_path1, 'r')\n",
    "loaded_model_json1 = json_file1.read()\n",
    "json_file1.close()\n",
    "loaded_model1 = model_from_json(loaded_model_json1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model weights\n",
    "weights_file_path1 = 'data/model_weights_clean.h5'\n",
    "loaded_model1.load_weights(weights_file_path1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizer for preprocessing\n",
    "tokenizer1 = Tokenizer()\n",
    "tokenizer_path1 = 'data/tokenizer_clean.pkl' \n",
    "with open(tokenizer_path1, 'rb') as handle:\n",
    "    tokenizer1 = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "Toxicity prediction cleaned: 0.9642\n"
     ]
    }
   ],
   "source": [
    "input_text1 = \"Trump is not like gay people, fancy blonde hair\"\n",
    "# Preprocess the input text\n",
    "sequence1 = tokenizer1.texts_to_sequences([input_text1])\n",
    "max_sequence_length1 = 100  # Adjust this based on your model's input shape\n",
    "padded_sequence1 = pad_sequences(sequence1, maxlen=max_sequence_length1)\n",
    "toxicity_prediction1 = loaded_model1.predict(padded_sequence1)\n",
    "toxicity_prediction_rounded1 = round(float(toxicity_prediction1), 4)\n",
    "print(\"Toxicity prediction cleaned:\", toxicity_prediction_rounded1)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ee5ce8695951d3743acb1574d7cbc518a435066b16546d59d44a9748127e061"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
