{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, TfidfVectorizer\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data load and %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/train.csv', nrows=1000)\n",
    "\n",
    "# Drop rows with null values in comment_text\n",
    "df_cleaned = data.dropna(subset=['comment_text'])\n",
    "df_train = df_cleaned[['comment_text','target']]\n",
    "\n",
    "# Add new column toxic, toxicity >= 0.5 then toxic = 1 otherwise toxic = 0\n",
    "df_train = df_train.copy()\n",
    "df_train['toxic'] = np.where(df_train['target'] >= 0.50, 1, 0)\n",
    "\n",
    "# Just remains toxic and comment_text\n",
    "df_train_small = df_train.drop(['target'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose % of the data load to use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using only 5% of dataset\n",
    "percentage = 100\n",
    "df_train_small = df_train_small.sample(frac=percentage / 100, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataframe that will include the results\n",
    "results_table = pd.DataFrame()\n",
    "\n",
    "def evaluate_model(model, X_train,y_train,X_test,y_test,results_df,model_name=\"\", parameters='', comments=''):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    # predict_probab = model.predict_proba(X_test)[:,1]\n",
    "    duration = time.time() - start_time\n",
    "    duration_format = f\"{int(duration // 60)} minutes and {round(duration % 60, 2)} seconds\"\n",
    "\n",
    "    # Calculating all metrics\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, predictions)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    conf_matrix = str(confusion_matrix(y_test, predictions))\n",
    "\n",
    "    # Create a dictionary including the results\n",
    "    results = {\n",
    "        'Name': model_name if model_name else model.__class__.__name__,\n",
    "        'Parameters': parameters,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': roc_auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Accuracy': accuracy,\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Training Time': duration_format,\n",
    "        'Comments': comments\n",
    "    }\n",
    "\n",
    "    # Convert the dictionary to a DataFrame\n",
    "    new_row_df = pd.DataFrame([results])\n",
    "    # don't forget to append the result to the results dataframe\n",
    "    results_df = pd.concat([results_df, new_row_df], ignore_index=True)\n",
    "\n",
    "    return results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM - Support Vector Machine model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **1. Text Preprocessing techniques**\n",
    "\n",
    "- **Tokenization**: Splitting text into sentences, words, or other units.\n",
    "- **Normalization**: Converting text to a standard form (e.g., lowercasing).\n",
    "- **Stemming and Lemmatization**: Reducing words to their base or root form.\n",
    "- **Stop Word Removal**: Eliminating common words that add little value in analysis.\n",
    "- **Handling Special Characters and Punctuation**.\n",
    "\n",
    "### **2. Feature Extraction techniques**\n",
    "\n",
    "- **Bag of Words (BoW)**: Represents text data as a bag of words (ignoring sequence/order).\n",
    "- **TF-IDF (Term Frequency-Inverse Document Frequency)**: Reflects how important a word is to a document in a collection.\n",
    "- **Word Embeddings**: Vector representations of words (e.g., Word2Vec, GloVe) that capture semantic meanings.\n",
    "- **Contextual Embeddings**: Advanced embeddings from models like BERT that consider the context of words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split train-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate data into features (X) and labels (y)\n",
    "X = df_train_small['comment_text']\n",
    "y = df_train_small['toxic']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TFDIF - SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andre/hh-ds-23-3/lexiguards/.venv/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# apply tfidf vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=8000)\n",
    "X_train_vectorized = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Instantiate\n",
    "svm_model = SVC(kernel='linear', probability=True)\n",
    "\n",
    "# Fit, predict and evaluate\n",
    "results_table = evaluate_model(svm_model, X_train_vectorized, y_train, X_test_vectorized, y_test,results_table, parameters=\"\", comments=\"SVM_tfidf\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC</td>\n",
       "      <td></td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.945</td>\n",
       "      <td>[[189   0]\\n [ 11   0]]</td>\n",
       "      <td>0 minutes and 0.45 seconds</td>\n",
       "      <td>SVM_tfidf</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Name Parameters  F1-Score  AUC-ROC  Precision  Recall  Accuracy  \\\n",
       "0  SVC                  0.0      0.5        0.0     0.0     0.945   \n",
       "\n",
       "          Confusion Matrix               Training Time   Comments  \n",
       "0  [[189   0]\\n [ 11   0]]  0 minutes and 0.45 seconds  SVM_tfidf  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC Curve and AUC:\n",
      "ROC-AUC: 0.6714766714766714\n"
     ]
    }
   ],
   "source": [
    "y_scores = svm_model.decision_function(X_test_vectorized)\n",
    "fpr, tpr, thresholds = roc_curve(y_test, y_scores)\n",
    "roc_auc = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "print(\"ROC Curve and AUC:\")\n",
    "print(f\"ROC-AUC: {roc_auc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
