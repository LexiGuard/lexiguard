{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ChnD36qHhuy"
      },
      "source": [
        "# XGBoost experiments (Michael)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLTUtsD6HupB"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nisbn3mTG0fj",
        "outputId": "c3a65a47-0bea-4de2-c594-1b5ca57dec48"
      },
      "outputs": [],
      "source": [
        "# import the usual suspects / basics\n",
        "import time; full_run_time_start = time.time() # start timing exec right away\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pickle\n",
        "from scipy import sparse\n",
        "import re\n",
        "\n",
        "# scikit-learn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score, classification_report, f1_score,\\\n",
        "    accuracy_score, precision_score, recall_score, confusion_matrix\n",
        "\n",
        "# XGBoost\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# currently not used and thus commented out\n",
        "# import nltk\n",
        "# nltk.download('wordnet')\n",
        "# nltk.download('omw-1.4')\n",
        "\n",
        "# display all df columns (default is 20)\n",
        "pd.options.display.max_columns = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Utility function for testing models and tracking results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "# empty df for storing results\n",
        "test_results = pd.DataFrame(columns=['model_name',\n",
        "                                'model_params',\n",
        "                                'data_desc',\n",
        "                                'data_size',\n",
        "                                'features_no',\n",
        "                                'f1',\n",
        "                                'acc',\n",
        "                                'recall',\n",
        "                                'prec',\n",
        "                                'roc_auc',\n",
        "                                'cf_matrix',\n",
        "                                'train_time',\n",
        "                                'notes'])\n",
        "\n",
        "def test_model(model, model_name, model_params, data_desc, X, y, notes=''):\n",
        "    '''\n",
        "    test_model(model, model_params, data_desc, X, y, notes='')\n",
        "    \n",
        "    Parameters:\n",
        "    -----------\n",
        "    model: instance of model to test\n",
        "    model_name: name of model\n",
        "    model_params: dict of (hyper)parameters passed to model\n",
        "    data_desc: description of dataset (preprocessing steps etc.)\n",
        "    X: feature array \n",
        "    y: target/label array\n",
        "    notes: additional notes (default: empty string)\n",
        "    '''\n",
        "\n",
        "    # Split data using default of 75% for train, 25% for test.\n",
        "    # Make sure test data has same toxic/nontoxic ratio as train data by\n",
        "    # using stratify parameter.\n",
        "    X_train, X_test, y_train, y_test =\\\n",
        "        train_test_split(X, y, stratify=y, random_state=42)\n",
        "    \n",
        "    # train model and time execution\n",
        "    train_time_start = time.time()\n",
        "    model.fit(X_train, y_train)\n",
        "    train_time = time.time() - train_time_start\n",
        "    train_time_str = f'{int(train_time // 60)}m {round(train_time % 60)}s'\n",
        "\n",
        "    # Make predictions on test set\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_proba = model.predict_proba(X_test)[:,1]\n",
        "\n",
        "    return {'model_name': model_name,\n",
        "            'model_params': model_params,\n",
        "            'data_desc': data_desc,\n",
        "            'data_size': X.shape[0],\n",
        "            'features_no': X.shape[1],\n",
        "            'f1': round(f1_score(y_test, y_pred), 3),\n",
        "            'acc': round(accuracy_score(y_test, y_pred), 3),\n",
        "            'recall': round(recall_score(y_test, y_pred), 3),\n",
        "            'prec': round(precision_score(y_test, y_pred), 3),\n",
        "            'roc_auc': round(roc_auc_score(y_test, y_pred_proba), 3),\n",
        "            'cf_matrix': confusion_matrix(y_test, y_pred),\n",
        "            'train_time': train_time_str,\n",
        "            'notes': notes}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "def store_test_result(result):\n",
        "    test_results.loc[len(test_results)] = result"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MP847vfIJMN"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(360301, 7)"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df = pd.read_csv('data/undersampled_data_60_40_ft.csv')\n",
        "df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "r6YNY0NIIL4d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(360835, 3)"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# new cleaned data\n",
        "df1 = pd.read_csv('data/data_usampl_60_40_comments_cleaned_preproc.csv')\n",
        "df1.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optional: Create smaller sample from data to speed up experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "sample_size = None\n",
        "\n",
        "# uncomment to create sample of desired size\n",
        "#sample_size = 25_000\n",
        "\n",
        "if sample_size != None:\n",
        "    # ratio toxic/nontoxic\n",
        "    tox_perc = 0.4\n",
        "    nontox_perc = 0.6\n",
        "\n",
        "    # number of toxic/nontoxic rows\n",
        "    sample_size_tox = int(sample_size * tox_perc)\n",
        "    sample_size_nontox = int(sample_size * nontox_perc)\n",
        "\n",
        "    sample_tox = df[df['toxic'] == 1].sample(sample_size_tox,\n",
        "                                             random_state=42)\n",
        "    sample_nontox = df[df['toxic'] == 0].sample(sample_size_nontox,\n",
        "                                                random_state=42)\n",
        "\n",
        "    df = pd.concat([sample_tox, sample_nontox])\n",
        "    print(f'Using sample ({df.shape[0]} rows).')\n",
        "\n",
        "else:\n",
        "    print(f'Using full data ({df.shape[0]} rows).')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop rows with NaN's"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rows with NaN's before dropping: 360301\n",
            "rows after: 360273\n",
            "rows dropped: 28\n"
          ]
        }
      ],
      "source": [
        "rows_before = df.shape[0]\n",
        "print(\"rows with NaN's before dropping:\", df.shape[0])\n",
        "df.dropna(inplace=True)\n",
        "df.reset_index(drop=True, inplace=True)\n",
        "print('rows after:', df.shape[0])\n",
        "print('rows dropped:', rows_before - df.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "rows with NaN's before dropping: 360835\n",
            "rows after: 360038\n",
            "rows dropped: 797\n"
          ]
        }
      ],
      "source": [
        "rows_before = df1.shape[0]\n",
        "print(\"rows with NaN's before dropping:\", df1.shape[0])\n",
        "df1.dropna(inplace=True)\n",
        "df1.reset_index(drop=True, inplace=True)\n",
        "print('rows after:', df1.shape[0])\n",
        "print('rows dropped:', rows_before - df1.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IbUc5bP0IUIS"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZffM2npRCPf"
      },
      "outputs": [],
      "source": [
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create label/target variable and check for imbalance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "29jE5PSrPFE2"
      },
      "outputs": [],
      "source": [
        "target = df['toxic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "target1 = df1['toxic']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "value_counts = target.value_counts()\n",
        "nontoxic_count = value_counts[0]\n",
        "toxic_count = value_counts[1]\n",
        "nontoxic_perc =\\\n",
        "    round((nontoxic_count / (nontoxic_count + toxic_count)) * 100, 1)\n",
        "toxic_perc =\\\n",
        "    round((toxic_count / (nontoxic_count + toxic_count)) * 100, 1)\n",
        "\n",
        "print(f'Nontoxic (0): {nontoxic_count} ({nontoxic_perc} %)')\n",
        "print(f'Toxic (1): {toxic_count} ({toxic_perc} %)')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Create various corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Raw corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp_raw = df['comment_text']\n",
        "corp_raw.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pre-processed corpus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(360273,)"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "corp_pp = df['stopwords_punct_lemma']\n",
        "corp_pp.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp_pp1 = df1['comment_clean_preproc']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Corpus of fastText vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# If smaller sample: Convert vector string in csv file to df\n",
        "# and cast all cols as float. This takes ~50 min for the full 360,000 rows.\n",
        "# --> If full data: Load pickle file to save time.\n",
        "\n",
        "if sample_size != None:\n",
        "    corp_ft = df['vector_fast_text'].str.strip('[]').str.split(expand=True)\n",
        "    corp_ft = corp_ft.astype('float')\n",
        "    display(corp_ft)\n",
        "    # with open('pickle/ft_vectors.pkl', mode='wb') as f:\n",
        "    #     pickle.dump(corp_ft, f)\n",
        "\n",
        "else:\n",
        "    with open('pickle/ft_vectors.pkl', mode='rb') as f:\n",
        "        corp_ft = pickle.load(f)\n",
        "    display(corp_ft)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of words (default)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vect_bow = CountVectorizer()\n",
        "corp_bow = vect_bow.fit_transform(corp_raw)\n",
        "corp_bow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of words (binary)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vect_bow_bin = CountVectorizer(binary=True)\n",
        "corp_bow_bin = vect_bow_bin.fit_transform(corp_raw)\n",
        "corp_bow_bin"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of words (mixed case)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vect_bow_mixc = CountVectorizer(lowercase=False)\n",
        "corp_bow_mixc = vect_bow_mixc.fit_transform(corp_raw)\n",
        "corp_bow_mixc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of words (default) on preprocessed comments (lemmatization, stopword and punctuation removal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<360273x123598 sparse matrix of type '<class 'numpy.int64'>'\n",
              "\twith 7419284 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vect_bow = CountVectorizer()\n",
        "corp_pp_bow = vect_bow.fit_transform(corp_pp)\n",
        "corp_pp_bow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "corp_pp_bow1 = vect_bow.fit_transform(corp_pp1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of 1/2-grams (default) on preprocessed comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vect_bo12grams = CountVectorizer(ngram_range=(1,2))\n",
        "corp_pp_bo12grams = vect_bo12grams.fit_transform(corp_pp)\n",
        "corp_pp_bo12grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of 1/2/3-grams (default) on preprocessed comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vect_bo123grams = CountVectorizer(ngram_range=(1,3))\n",
        "corp_pp_bo123grams = vect_bo123grams.fit_transform(corp_pp)\n",
        "corp_pp_bo123grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Bag of 2-grams (default) on preprocessed comments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vect_bo2grams = CountVectorizer(ngram_range=(2,2))\n",
        "corp_pp_bo2grams = vect_bo2grams.fit_transform(corp_pp)\n",
        "corp_pp_bo2grams"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tf_idf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vect_tfidf = TfidfVectorizer()\n",
        "corp_tfidf = vect_tfidf.fit_transform(corp_raw)\n",
        "corp_tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Tf_idf on preprocessed comments (lemmatization, stopword and punctuation removal)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vect_tfidf = TfidfVectorizer()\n",
        "corp_pp_tfidf = vect_tfidf.fit_transform(corp_pp)\n",
        "corp_pp_tfidf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Baseline model (logistic regression)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'max_iter': 2_000}\n",
        "\n",
        "# load model with parameters\n",
        "lr = LogisticRegression(**params)\n",
        "\n",
        "test_result = test_model(lr, 'BASELINE (logistic regression)', params,\n",
        "                    'bag of words', corp_bow, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## XGBoost experiments"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'bag of words',\n",
        "                         corp_bow, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'bag of words (binary)',\n",
        "                         corp_bow_bin, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'bag of words (mixed case)',\n",
        "                         corp_bow_mixc, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'bag of words (preprocessed)',\n",
        "                         corp_pp_bow, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "test_result = test_model(xgb, 'XGBoost', params, 'bag of words (preprocessed NEW)',\n",
        "                         corp_pp_bow1, target1)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params,\n",
        "                         'bag of 1/2-grams (preprocessed)',\n",
        "                         corp_pp_bo12grams, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # parameters for model\n",
        "# params = {'random_state': 42,\n",
        "#           'n_jobs': -1}\n",
        "\n",
        "# # load model with parameters\n",
        "# xgb = XGBClassifier(**params)\n",
        "\n",
        "# test_result = test_model(xgb, 'XGBoost', params,\n",
        "#                          'bag of 1/2/3-grams (preprocessed)',\n",
        "#                          corp_pp_bo123grams, target)\n",
        "# store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params,\n",
        "                         'bag of 2-grams (preprocessed)',\n",
        "                         corp_pp_bo2grams, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'tf_idf',\n",
        "                         corp_tfidf, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'tf_idf (preprocessed)',\n",
        "                         corp_pp_tfidf, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # parameters for model\n",
        "# params = {'random_state': 42,\n",
        "#           'n_jobs': -1,\n",
        "#           'n_estimators': 1000}\n",
        "\n",
        "# # load model with parameters\n",
        "# xgb = XGBClassifier(**params)\n",
        "\n",
        "# test_result = test_model(xgb, 'XGBoost', params, 'tf_idf (preprocessed)',\n",
        "#                          corp_pp_tfidf, target)\n",
        "# store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e2b5q-TtHlGq",
        "outputId": "2aa1220d-5ebf-47f0-888d-3ccbf7b1f1b2"
      },
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'fastText vectors',\n",
        "                         corp_ft, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# parameters for model\n",
        "params = {'random_state': 42,\n",
        "          'n_jobs': -1,\n",
        "          'n_estimators': 1000}\n",
        "\n",
        "# load model with parameters\n",
        "xgb = XGBClassifier(**params)\n",
        "\n",
        "test_result = test_model(xgb, 'XGBoost', params, 'fastText vectors',\n",
        "                         corp_ft, target)\n",
        "store_test_result(test_result)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Show test results + total exec time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>model_name</th>\n",
              "      <th>model_params</th>\n",
              "      <th>data_desc</th>\n",
              "      <th>data_size</th>\n",
              "      <th>features_no</th>\n",
              "      <th>f1</th>\n",
              "      <th>acc</th>\n",
              "      <th>recall</th>\n",
              "      <th>prec</th>\n",
              "      <th>roc_auc</th>\n",
              "      <th>cf_matrix</th>\n",
              "      <th>train_time</th>\n",
              "      <th>notes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1}</td>\n",
              "      <td>bag of words (preprocessed)</td>\n",
              "      <td>360273</td>\n",
              "      <td>123598</td>\n",
              "      <td>0.769</td>\n",
              "      <td>0.836</td>\n",
              "      <td>0.682</td>\n",
              "      <td>0.883</td>\n",
              "      <td>0.911</td>\n",
              "      <td>[[50710, 3275], [11483, 24601]]</td>\n",
              "      <td>0m 5s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBoost</td>\n",
              "      <td>{'random_state': 42, 'n_jobs': -1}</td>\n",
              "      <td>bag of words (preprocessed NEW)</td>\n",
              "      <td>360038</td>\n",
              "      <td>110371</td>\n",
              "      <td>0.773</td>\n",
              "      <td>0.839</td>\n",
              "      <td>0.687</td>\n",
              "      <td>0.885</td>\n",
              "      <td>0.913</td>\n",
              "      <td>[[50716, 3210], [11309, 24775]]</td>\n",
              "      <td>0m 5s</td>\n",
              "      <td></td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  model_name                        model_params  \\\n",
              "0    XGBoost  {'random_state': 42, 'n_jobs': -1}   \n",
              "1    XGBoost  {'random_state': 42, 'n_jobs': -1}   \n",
              "\n",
              "                         data_desc  data_size  features_no     f1    acc  \\\n",
              "0      bag of words (preprocessed)     360273       123598  0.769  0.836   \n",
              "1  bag of words (preprocessed NEW)     360038       110371  0.773  0.839   \n",
              "\n",
              "   recall   prec  roc_auc                        cf_matrix train_time notes  \n",
              "0   0.682  0.883    0.911  [[50710, 3275], [11483, 24601]]      0m 5s        \n",
              "1   0.687  0.885    0.913  [[50716, 3210], [11309, 24775]]      0m 5s        "
            ]
          },
          "execution_count": 22,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "full_run_time = time.time() - full_run_time_start\n",
        "print(f'Full run time: {int(full_run_time // 60)}m {round(full_run_time % 60)}s')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Other stuff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate average comment length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# characters\n",
        "comm_len_chars = df['comment_text'].apply(lambda s: len(s))\n",
        "avg_comm_len_chars = comm_len_chars.sum() / len(comm_len_chars)\n",
        "\n",
        "# words (rough count)\n",
        "comm_len_words = df['comment_text']\\\n",
        "    .apply(lambda s: len(re.findall(r'\\S+', s)))\n",
        "avg_comm_len_words = comm_len_words.sum() / len(comm_len_words)\n",
        "\n",
        "print('Average comment length:')\n",
        "print(round(avg_comm_len_chars), 'characters')\n",
        "print(round(avg_comm_len_words), 'words')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Calculate vocabulary size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pass"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
