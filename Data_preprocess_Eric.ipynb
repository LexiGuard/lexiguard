{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess Steps + Text Representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook we aim to create a CSV file with preprocessing steps like removing stop-words, punctuation, and lemmatization. Additionally we would like to add to the csv file the word vector representation using Spacy pre-trained models. We decided to store all these pre-steps in-order to reduce the amount of time and resources required when using different models. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set Up and data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this initialize tqdm which is useful to show a progress bar when applying operations in a pandas df\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the data used for this is the train.csv file originally from the kaggel competition\n",
    "data = pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of Columns : 2\n",
      "No of Rows : 1804874\n"
     ]
    }
   ],
   "source": [
    "# we only want to work out the comment text and keep the target including the toxicity score\n",
    "df_reduced = data[['comment_text','target']]\n",
    "print(f'No of Columns : {len(df_reduced.columns)}')\n",
    "print(f'No of Rows : {len(df_reduced)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4d/pzd0shj50snbbx917dflpkb80000gn/T/ipykernel_71613/2508876201.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_reduced['toxic'] = (df_reduced['target'] >= 0.5).astype(int)\n"
     ]
    }
   ],
   "source": [
    "# here we create a new column for the label that contains 1 if toxicity score is bigger than 0.5\n",
    "df_reduced['toxic'] = (df_reduced['target'] >= 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we do not need the toxicity score, we will keep only the label\n",
    "df = df_reduced.drop('target', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    3\n",
       "toxic           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check for any null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 3 NAs values wich will be removed with the following line\n",
    "df_clean = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "comment_text    0\n",
       "toxic           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#double check for NAs \n",
    "df_clean.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1804871, 2)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#we end with round about 1,8M rows\n",
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start with the preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Function - remove Stop Words & Punctuation, and convert to Lemma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load english language model and create nlp object from it\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Function\n",
    "def preprocess(text):\n",
    "    doc = nlp(text)\n",
    "\n",
    "    filtered_tokens = []\n",
    "\n",
    "    for token in doc:\n",
    "        if token.is_stop or token.is_punct:\n",
    "           continue\n",
    "        filtered_tokens.append(token.lemma_)\n",
    "\n",
    "    return \" \".join(filtered_tokens) #this convert the list into a string separated by spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_clean.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line below execute the function above and preprocess 1.8M of rows. Be patient when running it! \n",
    "#df['stopwords_punct_lemma'] = df['comment_text'].progress_apply(lambda text: preprocess(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/ericmartinez/neufische_bootcamp/lexiguards/Data_preprocess_Eric.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/ericmartinez/neufische_bootcamp/lexiguards/Data_preprocess_Eric.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m df\u001b[39m.\u001b[39;49mto_csv(\u001b[39m'\u001b[39;49m\u001b[39mdata/all_data_pp.csv\u001b[39;49m\u001b[39m'\u001b[39;49m, index\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/pandas/core/generic.py:3772\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[1;32m   3761\u001b[0m df \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m, ABCDataFrame) \u001b[39melse\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_frame()\n\u001b[1;32m   3763\u001b[0m formatter \u001b[39m=\u001b[39m DataFrameFormatter(\n\u001b[1;32m   3764\u001b[0m     frame\u001b[39m=\u001b[39mdf,\n\u001b[1;32m   3765\u001b[0m     header\u001b[39m=\u001b[39mheader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3769\u001b[0m     decimal\u001b[39m=\u001b[39mdecimal,\n\u001b[1;32m   3770\u001b[0m )\n\u001b[0;32m-> 3772\u001b[0m \u001b[39mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[39m.\u001b[39;49mto_csv(\n\u001b[1;32m   3773\u001b[0m     path_or_buf,\n\u001b[1;32m   3774\u001b[0m     lineterminator\u001b[39m=\u001b[39;49mlineterminator,\n\u001b[1;32m   3775\u001b[0m     sep\u001b[39m=\u001b[39;49msep,\n\u001b[1;32m   3776\u001b[0m     encoding\u001b[39m=\u001b[39;49mencoding,\n\u001b[1;32m   3777\u001b[0m     errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m   3778\u001b[0m     compression\u001b[39m=\u001b[39;49mcompression,\n\u001b[1;32m   3779\u001b[0m     quoting\u001b[39m=\u001b[39;49mquoting,\n\u001b[1;32m   3780\u001b[0m     columns\u001b[39m=\u001b[39;49mcolumns,\n\u001b[1;32m   3781\u001b[0m     index_label\u001b[39m=\u001b[39;49mindex_label,\n\u001b[1;32m   3782\u001b[0m     mode\u001b[39m=\u001b[39;49mmode,\n\u001b[1;32m   3783\u001b[0m     chunksize\u001b[39m=\u001b[39;49mchunksize,\n\u001b[1;32m   3784\u001b[0m     quotechar\u001b[39m=\u001b[39;49mquotechar,\n\u001b[1;32m   3785\u001b[0m     date_format\u001b[39m=\u001b[39;49mdate_format,\n\u001b[1;32m   3786\u001b[0m     doublequote\u001b[39m=\u001b[39;49mdoublequote,\n\u001b[1;32m   3787\u001b[0m     escapechar\u001b[39m=\u001b[39;49mescapechar,\n\u001b[1;32m   3788\u001b[0m     storage_options\u001b[39m=\u001b[39;49mstorage_options,\n\u001b[1;32m   3789\u001b[0m )\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/pandas/io/formats/format.py:1186\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[0;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[1;32m   1165\u001b[0m     created_buffer \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m   1167\u001b[0m csv_formatter \u001b[39m=\u001b[39m CSVFormatter(\n\u001b[1;32m   1168\u001b[0m     path_or_buf\u001b[39m=\u001b[39mpath_or_buf,\n\u001b[1;32m   1169\u001b[0m     lineterminator\u001b[39m=\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1184\u001b[0m     formatter\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfmt,\n\u001b[1;32m   1185\u001b[0m )\n\u001b[0;32m-> 1186\u001b[0m csv_formatter\u001b[39m.\u001b[39;49msave()\n\u001b[1;32m   1188\u001b[0m \u001b[39mif\u001b[39;00m created_buffer:\n\u001b[1;32m   1189\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/pandas/io/formats/csvs.py:259\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    240\u001b[0m \u001b[39mwith\u001b[39;00m get_handle(\n\u001b[1;32m    241\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilepath_or_buffer,\n\u001b[1;32m    242\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    247\u001b[0m ) \u001b[39mas\u001b[39;00m handles:\n\u001b[1;32m    248\u001b[0m     \u001b[39m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[1;32m    249\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwriter \u001b[39m=\u001b[39m csvlib\u001b[39m.\u001b[39mwriter(\n\u001b[1;32m    250\u001b[0m         handles\u001b[39m.\u001b[39mhandle,\n\u001b[1;32m    251\u001b[0m         lineterminator\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlineterminator,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    256\u001b[0m         quotechar\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mquotechar,\n\u001b[1;32m    257\u001b[0m     )\n\u001b[0;32m--> 259\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save()\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/pandas/io/formats/csvs.py:264\u001b[0m, in \u001b[0;36mCSVFormatter._save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    262\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_need_to_save_header:\n\u001b[1;32m    263\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_save_header()\n\u001b[0;32m--> 264\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_body()\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/pandas/io/formats/csvs.py:302\u001b[0m, in \u001b[0;36mCSVFormatter._save_body\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    300\u001b[0m \u001b[39mif\u001b[39;00m start_i \u001b[39m>\u001b[39m\u001b[39m=\u001b[39m end_i:\n\u001b[1;32m    301\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[0;32m--> 302\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_chunk(start_i, end_i)\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/pandas/io/formats/csvs.py:313\u001b[0m, in \u001b[0;36mCSVFormatter._save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m    310\u001b[0m data \u001b[39m=\u001b[39m [res\u001b[39m.\u001b[39miget_values(i) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(res\u001b[39m.\u001b[39mitems))]\n\u001b[1;32m    312\u001b[0m ix \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdata_index[slicer]\u001b[39m.\u001b[39m_format_native_types(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_number_format)\n\u001b[0;32m--> 313\u001b[0m libwriters\u001b[39m.\u001b[39;49mwrite_csv_rows(\n\u001b[1;32m    314\u001b[0m     data,\n\u001b[1;32m    315\u001b[0m     ix,\n\u001b[1;32m    316\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnlevels,\n\u001b[1;32m    317\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcols,\n\u001b[1;32m    318\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mwriter,\n\u001b[1;32m    319\u001b[0m )\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/pandas/_libs/writers.pyx:72\u001b[0m, in \u001b[0;36mpandas._libs.writers.write_csv_rows\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:1592\u001b[0m, in \u001b[0;36m_array_str_implementation\u001b[0;34m(a, max_line_width, precision, suppress_small, array2string)\u001b[0m\n\u001b[1;32m   1586\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39mshape \u001b[39m==\u001b[39m ():\n\u001b[1;32m   1587\u001b[0m     \u001b[39m# obtain a scalar and call str on it, avoiding problems for subclasses\u001b[39;00m\n\u001b[1;32m   1588\u001b[0m     \u001b[39m# for which indexing with () returns a 0d instead of a scalar by using\u001b[39;00m\n\u001b[1;32m   1589\u001b[0m     \u001b[39m# ndarray's getindex. Also guard against recursive 0d object arrays.\u001b[39;00m\n\u001b[1;32m   1590\u001b[0m     \u001b[39mreturn\u001b[39;00m _guarded_repr_or_str(np\u001b[39m.\u001b[39mndarray\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(a, ()))\n\u001b[0;32m-> 1592\u001b[0m \u001b[39mreturn\u001b[39;00m array2string(a, max_line_width, precision, suppress_small, \u001b[39m'\u001b[39;49m\u001b[39m \u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:736\u001b[0m, in \u001b[0;36marray2string\u001b[0;34m(a, max_line_width, precision, suppress_small, separator, prefix, style, formatter, threshold, edgeitems, sign, floatmode, suffix, legacy)\u001b[0m\n\u001b[1;32m    733\u001b[0m \u001b[39mif\u001b[39;00m a\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m    734\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m[]\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m--> 736\u001b[0m \u001b[39mreturn\u001b[39;00m _array2string(a, options, separator, prefix)\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:513\u001b[0m, in \u001b[0;36m_recursive_guard.<locals>.decorating_function.<locals>.wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    511\u001b[0m repr_running\u001b[39m.\u001b[39madd(key)\n\u001b[1;32m    512\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 513\u001b[0m     \u001b[39mreturn\u001b[39;00m f(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    514\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    515\u001b[0m     repr_running\u001b[39m.\u001b[39mdiscard(key)\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:539\u001b[0m, in \u001b[0;36m_array2string\u001b[0;34m(a, options, separator, prefix)\u001b[0m\n\u001b[1;32m    536\u001b[0m     summary_insert \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    538\u001b[0m \u001b[39m# find the right formatting function for the array\u001b[39;00m\n\u001b[0;32m--> 539\u001b[0m format_function \u001b[39m=\u001b[39m _get_format_function(data, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    541\u001b[0m \u001b[39m# skip over \"[\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m next_line_prefix \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:472\u001b[0m, in \u001b[0;36m_get_format_function\u001b[0;34m(data, **options)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[39mreturn\u001b[39;00m formatdict[\u001b[39m'\u001b[39m\u001b[39mlongfloat\u001b[39m\u001b[39m'\u001b[39m]()\n\u001b[1;32m    471\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 472\u001b[0m         \u001b[39mreturn\u001b[39;00m formatdict[\u001b[39m'\u001b[39;49m\u001b[39mfloat\u001b[39;49m\u001b[39m'\u001b[39;49m]()\n\u001b[1;32m    473\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39missubclass\u001b[39m(dtypeobj, _nt\u001b[39m.\u001b[39mcomplexfloating):\n\u001b[1;32m    474\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39missubclass\u001b[39m(dtypeobj, _nt\u001b[39m.\u001b[39mclongfloat):\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:411\u001b[0m, in \u001b[0;36m_get_formatdict.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    403\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_formatdict\u001b[39m(data, \u001b[39m*\u001b[39m, precision, floatmode, suppress, sign, legacy,\n\u001b[1;32m    404\u001b[0m                     formatter, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    405\u001b[0m     \u001b[39m# note: extra arguments in kwargs are ignored\u001b[39;00m\n\u001b[1;32m    406\u001b[0m \n\u001b[1;32m    407\u001b[0m     \u001b[39m# wrapped in lambdas to avoid taking a code path with the wrong type of data\u001b[39;00m\n\u001b[1;32m    408\u001b[0m     formatdict \u001b[39m=\u001b[39m {\n\u001b[1;32m    409\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mbool\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: BoolFormat(data),\n\u001b[1;32m    410\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mint\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: IntegerFormat(data),\n\u001b[0;32m--> 411\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mfloat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: FloatingFormat(\n\u001b[1;32m    412\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[39m=\u001b[39;49mlegacy),\n\u001b[1;32m    413\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlongfloat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: FloatingFormat(\n\u001b[1;32m    414\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[39m=\u001b[39mlegacy),\n\u001b[1;32m    415\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mcomplexfloat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: ComplexFloatingFormat(\n\u001b[1;32m    416\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[39m=\u001b[39mlegacy),\n\u001b[1;32m    417\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mlongcomplexfloat\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: ComplexFloatingFormat(\n\u001b[1;32m    418\u001b[0m             data, precision, floatmode, suppress, sign, legacy\u001b[39m=\u001b[39mlegacy),\n\u001b[1;32m    419\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mdatetime\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: DatetimeFormat(data, legacy\u001b[39m=\u001b[39mlegacy),\n\u001b[1;32m    420\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mtimedelta\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: TimedeltaFormat(data),\n\u001b[1;32m    421\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mobject\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: _object_format,\n\u001b[1;32m    422\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mvoid\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: str_format,\n\u001b[1;32m    423\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mnumpystr\u001b[39m\u001b[39m'\u001b[39m: \u001b[39mlambda\u001b[39;00m: repr_format}\n\u001b[1;32m    425\u001b[0m     \u001b[39m# we need to wrap values in `formatter` in a lambda, so that the interface\u001b[39;00m\n\u001b[1;32m    426\u001b[0m     \u001b[39m# is the same as the above values.\u001b[39;00m\n\u001b[1;32m    427\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mindirect\u001b[39m(x):\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:932\u001b[0m, in \u001b[0;36mFloatingFormat.__init__\u001b[0;34m(self, data, precision, floatmode, suppress_small, sign, legacy)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexp_format \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    930\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlarge_exponent \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 932\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfillFormat(data)\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:963\u001b[0m, in \u001b[0;36mFloatingFormat.fillFormat\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    959\u001b[0m     trim, unique \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    960\u001b[0m strs \u001b[39m=\u001b[39m (dragon4_scientific(x, precision\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision,\n\u001b[1;32m    961\u001b[0m                    unique\u001b[39m=\u001b[39munique, trim\u001b[39m=\u001b[39mtrim, sign\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msign \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    962\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m finite_vals)\n\u001b[0;32m--> 963\u001b[0m frac_strs, _, exp_strs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39;49m(\u001b[39m*\u001b[39;49m(s\u001b[39m.\u001b[39;49mpartition(\u001b[39m'\u001b[39;49m\u001b[39me\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m strs))\n\u001b[1;32m    964\u001b[0m int_part, frac_part \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(s\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m frac_strs))\n\u001b[1;32m    965\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexp_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m exp_strs) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:963\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    959\u001b[0m     trim, unique \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    960\u001b[0m strs \u001b[39m=\u001b[39m (dragon4_scientific(x, precision\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision,\n\u001b[1;32m    961\u001b[0m                    unique\u001b[39m=\u001b[39munique, trim\u001b[39m=\u001b[39mtrim, sign\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msign \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    962\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m finite_vals)\n\u001b[0;32m--> 963\u001b[0m frac_strs, _, exp_strs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(s\u001b[39m.\u001b[39;49mpartition(\u001b[39m'\u001b[39;49m\u001b[39me\u001b[39;49m\u001b[39m'\u001b[39;49m) \u001b[39mfor\u001b[39;49;00m s \u001b[39min\u001b[39;49;00m strs))\n\u001b[1;32m    964\u001b[0m int_part, frac_part \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(s\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m frac_strs))\n\u001b[1;32m    965\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexp_size \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mlen\u001b[39m(s) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m exp_strs) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n",
      "File \u001b[0;32m~/neufische_bootcamp/lexiguards/.venv/lib/python3.11/site-packages/numpy/core/arrayprint.py:960\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    958\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfloatmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mfixed\u001b[39m\u001b[39m'\u001b[39m \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_legacy \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m113\u001b[39m:\n\u001b[1;32m    959\u001b[0m     trim, unique \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mk\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m--> 960\u001b[0m strs \u001b[39m=\u001b[39m (dragon4_scientific(x, precision\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision,\n\u001b[1;32m    961\u001b[0m                    unique\u001b[39m=\u001b[39munique, trim\u001b[39m=\u001b[39mtrim, sign\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msign \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m    962\u001b[0m         \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m finite_vals)\n\u001b[1;32m    963\u001b[0m frac_strs, _, exp_strs \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(s\u001b[39m.\u001b[39mpartition(\u001b[39m'\u001b[39m\u001b[39me\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m strs))\n\u001b[1;32m    964\u001b[0m int_part, frac_part \u001b[39m=\u001b[39m \u001b[39mzip\u001b[39m(\u001b[39m*\u001b[39m(s\u001b[39m.\u001b[39msplit(\u001b[39m'\u001b[39m\u001b[39m.\u001b[39m\u001b[39m'\u001b[39m) \u001b[39mfor\u001b[39;00m s \u001b[39min\u001b[39;00m frac_strs))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# This line below was used to store temporarely the dataframe containing the preprocess comment text\n",
    "\n",
    "#df.to_csv('data/all_data_pp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line below load the data from the temporary file \n",
    "df1 = pd.read_csv('data/all_data_pp.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1804871/1804871 [3:26:37<00:00, 145.58it/s]  \n"
     ]
    }
   ],
   "source": [
    "# we used the large model from spacy to convert to do our text representation in vectors, this runs over 1.8 M rows again, be careful!\n",
    "nlp = spacy.load(\"en_core_web_lg\") # we load the model\n",
    "df['vector_spacy'] = df['stopwords_punct_lemma'].progress_apply(lambda text: nlp(text).vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this line was used to temporary safe the data with the vectors and the preprocess steps\n",
    "\n",
    "#df.to_csv('data/all_data_pp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge data with data from Pos tagging preprocess"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following part aims to merge the current preprocess steps with pos tagging process that were executed in a different workflow. The data is stored in a csv file called: pos_data.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pos = pd.read_csv('data/pos_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since comment text and toxic columns are in both datasets, I will remove it from one of them\n",
    "df_pos = df_pos.drop(['comment_text','toxic'],axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>pos_tags_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[('This', 'DT'), ('is', 'VBZ'), ('so', 'RB'), ...</td>\n",
       "      <td>DT VBZ RB JJ . PRP VBZ IN , FW PRP VBP PRP$ NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[('Thank', 'NNP'), ('you', 'PRP'), ('!', '.'),...</td>\n",
       "      <td>NNP PRP . . DT MD VB PRP$ NN DT NN JJR JJ . VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[('This', 'DT'), ('is', 'VBZ'), ('such', 'JJ')...</td>\n",
       "      <td>DT VBZ JJ DT JJ NN NN : VB TO PRP IN VBG PRP I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[('Is', 'VBZ'), ('this', 'DT'), ('something', ...</td>\n",
       "      <td>VBZ DT NN PRP MD VB JJ TO VB IN PRP$ NN . WRB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[('haha', 'NN'), ('you', 'PRP'), ('guys', 'NNS...</td>\n",
       "      <td>NN PRP NNS VBP DT NN IN NNS .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804866</th>\n",
       "      <td>[('Maybe', 'RB'), ('the', 'DT'), ('tax', 'NN')...</td>\n",
       "      <td>RB DT NN IN `` NNS '' MD VB VBN WRB DT NN VBZ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804867</th>\n",
       "      <td>[('What', 'WP'), ('do', 'VBP'), ('you', 'PRP')...</td>\n",
       "      <td>WP VBP PRP VB NNS WP VBP VBP DT NN VBD DT NN I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804868</th>\n",
       "      <td>[('thank', 'NN'), ('you', 'PRP'), (',', ','), ...</td>\n",
       "      <td>NN PRP , , , RB CC JJ , , , VBP VBP VBG PRP$ NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804869</th>\n",
       "      <td>[('Anyone', 'NN'), ('who', 'WP'), ('is', 'VBZ'...</td>\n",
       "      <td>NN WP VBZ VBN IN VBG DT JJ NN , RB IN JJ , MD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804870</th>\n",
       "      <td>[('Students', 'NNS'), ('defined', 'VBD'), ('as...</td>\n",
       "      <td>NNS VBD IN NNP VBP RB RB IN JJ CC JJ IN JJ NNS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1804871 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  pos_tags  \\\n",
       "0        [('This', 'DT'), ('is', 'VBZ'), ('so', 'RB'), ...   \n",
       "1        [('Thank', 'NNP'), ('you', 'PRP'), ('!', '.'),...   \n",
       "2        [('This', 'DT'), ('is', 'VBZ'), ('such', 'JJ')...   \n",
       "3        [('Is', 'VBZ'), ('this', 'DT'), ('something', ...   \n",
       "4        [('haha', 'NN'), ('you', 'PRP'), ('guys', 'NNS...   \n",
       "...                                                    ...   \n",
       "1804866  [('Maybe', 'RB'), ('the', 'DT'), ('tax', 'NN')...   \n",
       "1804867  [('What', 'WP'), ('do', 'VBP'), ('you', 'PRP')...   \n",
       "1804868  [('thank', 'NN'), ('you', 'PRP'), (',', ','), ...   \n",
       "1804869  [('Anyone', 'NN'), ('who', 'WP'), ('is', 'VBZ'...   \n",
       "1804870  [('Students', 'NNS'), ('defined', 'VBD'), ('as...   \n",
       "\n",
       "                                              pos_tags_str  \n",
       "0        DT VBZ RB JJ . PRP VBZ IN , FW PRP VBP PRP$ NN...  \n",
       "1        NNP PRP . . DT MD VB PRP$ NN DT NN JJR JJ . VB...  \n",
       "2        DT VBZ JJ DT JJ NN NN : VB TO PRP IN VBG PRP I...  \n",
       "3        VBZ DT NN PRP MD VB JJ TO VB IN PRP$ NN . WRB ...  \n",
       "4                            NN PRP NNS VBP DT NN IN NNS .  \n",
       "...                                                    ...  \n",
       "1804866  RB DT NN IN `` NNS '' MD VB VBN WRB DT NN VBZ ...  \n",
       "1804867  WP VBP PRP VB NNS WP VBP VBP DT NN VBD DT NN I...  \n",
       "1804868    NN PRP , , , RB CC JJ , , , VBP VBP VBG PRP$ NN  \n",
       "1804869  NN WP VBZ VBN IN VBG DT JJ NN , RB IN JJ , MD ...  \n",
       "1804870  NNS VBD IN NNP VBP RB RB IN JJ CC JJ IN JJ NNS...  \n",
       "\n",
       "[1804871 rows x 2 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Since the index of both dataframe should be the same to merge a reset index in df is necessary. The old index will be remove.\n",
    "df_to_merge = df.reset_index()\n",
    "df_to_merge = df_to_merge.drop('index',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here are both dataframes merged\n",
    "merged_pp_df = pd.merge(df_to_merge, df_pos, left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>stopwords_punct_lemma</th>\n",
       "      <th>vector_spacy</th>\n",
       "      <th>pos_tags</th>\n",
       "      <th>pos_tags_str</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is so cool. It's like, 'would you want yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>cool like want mother read great idea</td>\n",
       "      <td>[0.57358134, 0.40742856, -2.652657, -2.6345057...</td>\n",
       "      <td>[('This', 'DT'), ('is', 'VBZ'), ('so', 'RB'), ...</td>\n",
       "      <td>DT VBZ RB JJ . PRP VBZ IN , FW PRP VBP PRP$ NN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Thank you!! This would make my life a lot less...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank life lot anxiety inducing let way</td>\n",
       "      <td>[2.3985057, 0.08947158, -3.6875572, -0.9417053...</td>\n",
       "      <td>[('Thank', 'NNP'), ('you', 'PRP'), ('!', '.'),...</td>\n",
       "      <td>NNP PRP . . DT MD VB PRP$ NN DT NN JJR JJ . VB...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is such an urgent design problem; kudos t...</td>\n",
       "      <td>0</td>\n",
       "      <td>urgent design problem kudo take impressive</td>\n",
       "      <td>[0.9049366, 1.0650175, -1.8506068, -0.6678533,...</td>\n",
       "      <td>[('This', 'DT'), ('is', 'VBZ'), ('such', 'JJ')...</td>\n",
       "      <td>DT VBZ JJ DT JJ NN NN : VB TO PRP IN VBG PRP I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Is this something I'll be able to install on m...</td>\n",
       "      <td>0</td>\n",
       "      <td>able install site release</td>\n",
       "      <td>[2.15365, 0.84712, -1.303075, -1.1850657, 1.32...</td>\n",
       "      <td>[('Is', 'VBZ'), ('this', 'DT'), ('something', ...</td>\n",
       "      <td>VBZ DT NN PRP MD VB JJ TO VB IN PRP$ NN . WRB ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>haha you guys are a bunch of losers.</td>\n",
       "      <td>1</td>\n",
       "      <td>haha guy bunch loser</td>\n",
       "      <td>[-1.30565, -1.2035375, -1.544195, -0.53491247,...</td>\n",
       "      <td>[('haha', 'NN'), ('you', 'PRP'), ('guys', 'NNS...</td>\n",
       "      <td>NN PRP NNS VBP DT NN IN NNS .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804866</th>\n",
       "      <td>Maybe the tax on \"things\" would be collected w...</td>\n",
       "      <td>0</td>\n",
       "      <td>maybe tax thing collect product import registe...</td>\n",
       "      <td>[-1.74022, -1.2526344, -1.8042428, -0.02307643...</td>\n",
       "      <td>[('Maybe', 'RB'), ('the', 'DT'), ('tax', 'NN')...</td>\n",
       "      <td>RB DT NN IN `` NNS '' MD VB VBN WRB DT NN VBZ ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804867</th>\n",
       "      <td>What do you call people who STILL think the di...</td>\n",
       "      <td>0</td>\n",
       "      <td>people think divine role creation</td>\n",
       "      <td>[-1.804096, 1.24632, -1.8707399, -1.5715679, 2...</td>\n",
       "      <td>[('What', 'WP'), ('do', 'VBP'), ('you', 'PRP')...</td>\n",
       "      <td>WP VBP PRP VB NNS WP VBP VBP DT NN VBD DT NN I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804868</th>\n",
       "      <td>thank you ,,,right or wrong,,, i am following ...</td>\n",
       "      <td>0</td>\n",
       "      <td>thank right wrong follow advice</td>\n",
       "      <td>[1.060516, 0.04716005, -1.3738799, -1.42328, 0...</td>\n",
       "      <td>[('thank', 'NN'), ('you', 'PRP'), (',', ','), ...</td>\n",
       "      <td>NN PRP , , , RB CC JJ , , , VBP VBP VBG PRP$ NN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804869</th>\n",
       "      <td>Anyone who is quoted as having the following e...</td>\n",
       "      <td>1</td>\n",
       "      <td>quote have follow exchange apocryphal receive ...</td>\n",
       "      <td>[-0.5423877, -0.25980785, -0.28140348, -0.7341...</td>\n",
       "      <td>[('Anyone', 'NN'), ('who', 'WP'), ('is', 'VBZ'...</td>\n",
       "      <td>NN WP VBZ VBN IN VBG DT JJ NN , RB IN JJ , MD ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804870</th>\n",
       "      <td>Students defined as EBD are legally just as di...</td>\n",
       "      <td>0</td>\n",
       "      <td>student define EBD legally disabled eligible s...</td>\n",
       "      <td>[-0.43380806, 0.5868807, -0.6954485, -0.609393...</td>\n",
       "      <td>[('Students', 'NNS'), ('defined', 'VBD'), ('as...</td>\n",
       "      <td>NNS VBD IN NNP VBP RB RB IN JJ CC JJ IN JJ NNS...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1804871 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              comment_text  toxic  \\\n",
       "0        This is so cool. It's like, 'would you want yo...      0   \n",
       "1        Thank you!! This would make my life a lot less...      0   \n",
       "2        This is such an urgent design problem; kudos t...      0   \n",
       "3        Is this something I'll be able to install on m...      0   \n",
       "4                     haha you guys are a bunch of losers.      1   \n",
       "...                                                    ...    ...   \n",
       "1804866  Maybe the tax on \"things\" would be collected w...      0   \n",
       "1804867  What do you call people who STILL think the di...      0   \n",
       "1804868  thank you ,,,right or wrong,,, i am following ...      0   \n",
       "1804869  Anyone who is quoted as having the following e...      1   \n",
       "1804870  Students defined as EBD are legally just as di...      0   \n",
       "\n",
       "                                     stopwords_punct_lemma  \\\n",
       "0                    cool like want mother read great idea   \n",
       "1                  thank life lot anxiety inducing let way   \n",
       "2               urgent design problem kudo take impressive   \n",
       "3                                able install site release   \n",
       "4                                     haha guy bunch loser   \n",
       "...                                                    ...   \n",
       "1804866  maybe tax thing collect product import registe...   \n",
       "1804867                  people think divine role creation   \n",
       "1804868                    thank right wrong follow advice   \n",
       "1804869  quote have follow exchange apocryphal receive ...   \n",
       "1804870  student define EBD legally disabled eligible s...   \n",
       "\n",
       "                                              vector_spacy  \\\n",
       "0        [0.57358134, 0.40742856, -2.652657, -2.6345057...   \n",
       "1        [2.3985057, 0.08947158, -3.6875572, -0.9417053...   \n",
       "2        [0.9049366, 1.0650175, -1.8506068, -0.6678533,...   \n",
       "3        [2.15365, 0.84712, -1.303075, -1.1850657, 1.32...   \n",
       "4        [-1.30565, -1.2035375, -1.544195, -0.53491247,...   \n",
       "...                                                    ...   \n",
       "1804866  [-1.74022, -1.2526344, -1.8042428, -0.02307643...   \n",
       "1804867  [-1.804096, 1.24632, -1.8707399, -1.5715679, 2...   \n",
       "1804868  [1.060516, 0.04716005, -1.3738799, -1.42328, 0...   \n",
       "1804869  [-0.5423877, -0.25980785, -0.28140348, -0.7341...   \n",
       "1804870  [-0.43380806, 0.5868807, -0.6954485, -0.609393...   \n",
       "\n",
       "                                                  pos_tags  \\\n",
       "0        [('This', 'DT'), ('is', 'VBZ'), ('so', 'RB'), ...   \n",
       "1        [('Thank', 'NNP'), ('you', 'PRP'), ('!', '.'),...   \n",
       "2        [('This', 'DT'), ('is', 'VBZ'), ('such', 'JJ')...   \n",
       "3        [('Is', 'VBZ'), ('this', 'DT'), ('something', ...   \n",
       "4        [('haha', 'NN'), ('you', 'PRP'), ('guys', 'NNS...   \n",
       "...                                                    ...   \n",
       "1804866  [('Maybe', 'RB'), ('the', 'DT'), ('tax', 'NN')...   \n",
       "1804867  [('What', 'WP'), ('do', 'VBP'), ('you', 'PRP')...   \n",
       "1804868  [('thank', 'NN'), ('you', 'PRP'), (',', ','), ...   \n",
       "1804869  [('Anyone', 'NN'), ('who', 'WP'), ('is', 'VBZ'...   \n",
       "1804870  [('Students', 'NNS'), ('defined', 'VBD'), ('as...   \n",
       "\n",
       "                                              pos_tags_str  \n",
       "0        DT VBZ RB JJ . PRP VBZ IN , FW PRP VBP PRP$ NN...  \n",
       "1        NNP PRP . . DT MD VB PRP$ NN DT NN JJR JJ . VB...  \n",
       "2        DT VBZ JJ DT JJ NN NN : VB TO PRP IN VBG PRP I...  \n",
       "3        VBZ DT NN PRP MD VB JJ TO VB IN PRP$ NN . WRB ...  \n",
       "4                            NN PRP NNS VBP DT NN IN NNS .  \n",
       "...                                                    ...  \n",
       "1804866  RB DT NN IN `` NNS '' MD VB VBN WRB DT NN VBZ ...  \n",
       "1804867  WP VBP PRP VB NNS WP VBP VBP DT NN VBD DT NN I...  \n",
       "1804868    NN PRP , , , RB CC JJ , , , VBP VBP VBG PRP$ NN  \n",
       "1804869  NN WP VBZ VBN IN VBG DT JJ NN , RB IN JJ , MD ...  \n",
       "1804870  NNS VBD IN NNP VBP RB RB IN JJ CC JJ IN JJ NNS...  \n",
       "\n",
       "[1804871 rows x 6 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_pp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This below line is used to temporary safe the data in a csv file\n",
    "\n",
    "#merged_pp_df.to_csv('data/merged_pp_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
