{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model for a toxic classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.dummy import DummyClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/merged_data.csv')\n",
    "data = df[['comment_text','toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset contains {} instances of {} variables.\".format(data.shape[0], data.shape[1]))\n",
    "\n",
    "print(\n",
    "    \"It contains {} toxic messages ({:.1%} of all).\".format(\n",
    "        data[data.toxic == 1].shape[0],\n",
    "        data[data.toxic == 1].shape[0] / data.shape[0],\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data in train and test\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(data['comment_text'], data['toxic'], random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check Data Sizes\n",
    "print(X_train.shape, Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer or Bag of Words - Uni-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the CountVectorizer to the training data\n",
    "\n",
    "vect = CountVectorizer(binary=True).fit(X_train)\n",
    "\n",
    "# transform the different comments in the training data to a sparse matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1500)\n",
    "model.fit(X_train_vectorized, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform the test data\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "#Do predictions\n",
    "predictions = model.predict(X_test_vectorized)\n",
    "#Evaluation\n",
    "print(roc_auc_score(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer or Bag of Words - Bi-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the CountVectorizer to the training data\n",
    "\n",
    "vect = CountVectorizer(binary=True, ngram_range=(1,2)).fit(X_train)\n",
    "\n",
    "# transform the different comments in the training data to a sparse matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1500)\n",
    "model.fit(X_train_vectorized, Y_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "#Do predictions\n",
    "predictions = model.predict(X_test_vectorized)\n",
    "#Evaluation\n",
    "print(roc_auc_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer or Bag of Words - Tri-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the CountVectorizer to the training data\n",
    "\n",
    "vect = CountVectorizer(binary=True, ngram_range=(1,3)).fit(X_train)\n",
    "\n",
    "# transform the different comments in the training data to a sparse matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "\n",
    "# Train the model\n",
    "model = LogisticRegression(max_iter=1500)\n",
    "model.fit(X_train_vectorized, Y_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "#Do predictions\n",
    "predictions = model.predict(X_test_vectorized)\n",
    "#Evaluation\n",
    "print(roc_auc_score(Y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the feature names as numpy array\n",
    "feature_names = np.array(vect.get_feature_names_out())\n",
    "\n",
    "# Sort the coefficients from the model (from lowest to highest values)\n",
    "sorted_coef_index = model.coef_[0].argsort()\n",
    "\n",
    "# Find the 10 smallest and 10 largest coefficients\n",
    "# The 10 largest coefficients are being indexed using [:-11:-1]\n",
    "# so the list returned is in order of largest to smallest\n",
    "print(\"Smallest Coefs:\\n{}\\n\".format(feature_names[sorted_coef_index[:10]]))\n",
    "print(\"Largest Coefs: \\n{}\".format(feature_names[sorted_coef_index[:-11:-1]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF\n",
    "\n",
    "**Term Frequency - Inverse Document Frequency**\n",
    "\n",
    "Main idea: It measure how important a word is to a document in a set of texts . \n",
    "\n",
    "Term Frequency (TF): This is the number of times a word appears in a document, divided by the total number of words in that document. It gives higher value to terms that appear more frequently in a particular document.\n",
    "\n",
    "Inverse Document Frequency (IDF): This measures the importance of the term across the corpus. It is calculated as the logarithm of the number of documents divided by the number of documents that contain the word. This means common words like 'the', which appear in many documents, will have a lower IDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer with min_df\n",
    "tfidf_vect = TfidfVectorizer(min_df=30) \n",
    "\n",
    "# Fit and transform the training data to a document-term matrix\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "\n",
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#initialize and train the model with a the tfidf data_transformation\n",
    "model = LogisticRegression(max_iter=1500)\n",
    "model.fit(X_train_tfidf, Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "predictions = model.predict(X_test_tfidf)\n",
    "print(roc_auc_score(Y_test, predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dummy_classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#First we initialize the dummy_clf\n",
    "dummy_clf = DummyClassifier(strategy=\"most_frequent\")\n",
    "\n",
    "#we train it\n",
    "dummy_clf.fit(X_train, Y_train)\n",
    "\n",
    "#we evaluate it\n",
    "dummy_predictions = dummy_clf.predict(X_test)\n",
    "print(roc_auc_score(Y_test, dummy_predictions))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
