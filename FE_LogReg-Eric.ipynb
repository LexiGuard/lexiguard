{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/ericmartinez/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/ericmartinez/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "import spacy\n",
    "import nltk # natural language tool kit\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk import ngrams\n",
    "from collections import Counter\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('data/merged_data.csv')\n",
    "df_train = data[['comment_text','toxic']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nThis alternative data is to go with a bigger data set\\ndata = pd.read_csv('data/train.csv')\\ndf_cleaned = data.dropna(subset=['comment_text'])\\ndf_train = df_cleaned[['comment_text','target']]\\n\""
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "This alternative data is to go with a bigger data set\n",
    "data = pd.read_csv('data/train.csv')\n",
    "df_cleaned = data.dropna(subset=['comment_text'])\n",
    "df_train = df_cleaned[['comment_text','target']]\n",
    "# Add new column toxic, toxicity >= 0.5 then toxic = 1 otherwise toxic = 0\n",
    "df_train = df_train.copy()\n",
    "df_train['toxic'] = np.where(df_train['target'] >= 0.50, 1, 0)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split Train and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split the data in train and test\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_train['comment_text'], df_train['toxic'], random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to record different models performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataframe that will include the results\n",
    "results_df = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X_train,y_train,X_test,y_test, model_name=\"\", parameters='', comments=''):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    predict_probab = model.predict_proba(X_test)[:,1]\n",
    "    duration = time.time() - start_time\n",
    "    duration_format = f\"{int(duration // 60)} minutes and {round(duration % 60, 2)} seconds\"\n",
    "\n",
    "    # Calculating all metrics\n",
    "\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, predict_probab)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    conf_matrix = str(confusion_matrix(y_test, predictions))\n",
    "\n",
    "    # Create a dictionary including the results\n",
    "    results = {\n",
    "        'Name': model_name if model_name else model.__class__.__name__,\n",
    "        'Parameters': parameters,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': roc_auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Accuracy': accuracy,\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Training Time': duration_format,\n",
    "        'Comments': comments\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Baseline Model (Bag of Words + LogisticRegression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fit the CountVectorizer to the training data\n",
    "vect = CountVectorizer(binary=True).fit(X_train)\n",
    "\n",
    "# Prepare X_train for the function, transforming the different comments in the training data to a sparse matrix\n",
    "X_train_vectorized = vect.transform(X_train)\n",
    "# Prepare X_test for the function\n",
    "X_test_vectorized = vect.transform(X_test)\n",
    "\n",
    "# Initialize the model you want to try\n",
    "model = LogisticRegression(max_iter=1500)\n",
    "\n",
    "\n",
    "# Call the function and store the row in the variable result\n",
    "result = evaluate_model(model, X_train_vectorized, y_train, X_test_vectorized, y_test, parameters=\"binary\", comments=\"Baseline\" )\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "new_row_df = pd.DataFrame([result])\n",
    "# don't forget to append the result to the results dataframe\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_df)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF - IDF + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the TfidfVectorizer with min_df\n",
    "tfidf_vect = TfidfVectorizer(min_df=30)\n",
    "\n",
    "# Prepare X_train for the function\n",
    "X_train_tfidf = tfidf_vect.fit_transform(X_train)\n",
    "\n",
    "# Prepare X_test for the function\n",
    "X_test_tfidf = tfidf_vect.transform(X_test)\n",
    "\n",
    "# Initialize the model you want to try\n",
    "model = LogisticRegression(max_iter=1500)\n",
    "\n",
    "# Call the function and store the row in the variable result\n",
    "result = evaluate_model(model, X_train_tfidf, y_train, X_test_tfidf, y_test, parameters=\"min_df=30\", comments=\"TfidfVectorizer\" )\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "new_row_df = pd.DataFrame([result])\n",
    "# don't forget to append the result to the results dataframe\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_df)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.539521</td>\n",
       "      <td>0.888785</td>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.447341</td>\n",
       "      <td>0.913705</td>\n",
       "      <td>[[96673  2670]\\n [ 6995  5662]]</td>\n",
       "      <td>0 minutes and 27.88 seconds</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>min_df=30</td>\n",
       "      <td>0.507491</td>\n",
       "      <td>0.916806</td>\n",
       "      <td>0.769095</td>\n",
       "      <td>0.378684</td>\n",
       "      <td>0.916937</td>\n",
       "      <td>[[97904  1439]\\n [ 7864  4793]]</td>\n",
       "      <td>0 minutes and 7.0 seconds</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name Parameters  F1-Score   AUC-ROC  Precision    Recall  \\\n",
       "0  LogisticRegression     binary  0.539521  0.888785   0.679549  0.447341   \n",
       "1  LogisticRegression  min_df=30  0.507491  0.916806   0.769095  0.378684   \n",
       "\n",
       "   Accuracy                 Confusion Matrix                Training Time  \\\n",
       "0  0.913705  [[96673  2670]\\n [ 6995  5662]]  0 minutes and 27.88 seconds   \n",
       "1  0.916937  [[97904  1439]\\n [ 7864  4793]]    0 minutes and 7.0 seconds   \n",
       "\n",
       "          Comments  \n",
       "0         Baseline  \n",
       "1  TfidfVectorizer  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocess techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming(Bag of words) + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Initializing stemmer and countvectorizer \n",
    "stemmer = nltk.PorterStemmer()\n",
    "cv_analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    ''' \n",
    "    In this function the text is first passed through the build_analyzer() and then each word in the text is stemmed to its base form\n",
    "    '''\n",
    "    return (stemmer.stem(w) for w in cv_analyzer(doc))\n",
    "\n",
    "# define CountVectorizer with stemming function \n",
    "stem_vectorizer = CountVectorizer(analyzer = stemmed_words)\n",
    "\n",
    "# Prepare X_train for the function\n",
    "X_train_stem_vectorized = stem_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Prepare X_test for the function\n",
    "X_test_stem_vectorized = stem_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the model you want to try\n",
    "model = LogisticRegression(max_iter=2500)\n",
    "\n",
    "# Call the function and store the row in the variable result\n",
    "result = evaluate_model(model, X_train_stem_vectorized, y_train, X_test_stem_vectorized, y_test, parameters=\"\", comments=\"Stemming+LogisticRegression\")\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "new_row_df = pd.DataFrame([result])\n",
    "# don't forget to append the result to the results dataframe\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_df)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.539521</td>\n",
       "      <td>0.888785</td>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.447341</td>\n",
       "      <td>0.913705</td>\n",
       "      <td>[[96673  2670]\\n [ 6995  5662]]</td>\n",
       "      <td>0 minutes and 27.88 seconds</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>min_df=30</td>\n",
       "      <td>0.507491</td>\n",
       "      <td>0.916806</td>\n",
       "      <td>0.769095</td>\n",
       "      <td>0.378684</td>\n",
       "      <td>0.916937</td>\n",
       "      <td>[[97904  1439]\\n [ 7864  4793]]</td>\n",
       "      <td>0 minutes and 7.0 seconds</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td></td>\n",
       "      <td>0.519429</td>\n",
       "      <td>0.883760</td>\n",
       "      <td>0.688127</td>\n",
       "      <td>0.417160</td>\n",
       "      <td>0.912768</td>\n",
       "      <td>[[96950  2393]\\n [ 7377  5280]]</td>\n",
       "      <td>0 minutes and 44.53 seconds</td>\n",
       "      <td>Stemming+LogisticRegression</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name Parameters  F1-Score   AUC-ROC  Precision    Recall  \\\n",
       "0  LogisticRegression     binary  0.539521  0.888785   0.679549  0.447341   \n",
       "1  LogisticRegression  min_df=30  0.507491  0.916806   0.769095  0.378684   \n",
       "2  LogisticRegression             0.519429  0.883760   0.688127  0.417160   \n",
       "\n",
       "   Accuracy                 Confusion Matrix                Training Time  \\\n",
       "0  0.913705  [[96673  2670]\\n [ 6995  5662]]  0 minutes and 27.88 seconds   \n",
       "1  0.916937  [[97904  1439]\\n [ 7864  4793]]    0 minutes and 7.0 seconds   \n",
       "2  0.912768  [[96950  2393]\\n [ 7377  5280]]  0 minutes and 44.53 seconds   \n",
       "\n",
       "                      Comments  \n",
       "0                     Baseline  \n",
       "1              TfidfVectorizer  \n",
       "2  Stemming+LogisticRegression  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stemming(Bag of words(stopwords)) + LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "                         \n",
    "# stop_words contains a list of 179 words that we want to remove from our comments\n",
    "\n",
    "# Initializing stemmer and countvectorizer with Stop Words\n",
    "stemmer = nltk.PorterStemmer()\n",
    "cv_analyzer = CountVectorizer(stop_words=list(stop_words)).build_analyzer()\n",
    "\n",
    "def stemmed_words(doc):\n",
    "    ''' \n",
    "    In this function the text is first passed through the build_analyzer() and then each word in the text is stemmed to its base form\n",
    "    '''\n",
    "    return (stemmer.stem(w) for w in cv_analyzer(doc))\n",
    "\n",
    "# define CountVectorizer with stemming function \n",
    "stem_vectorizer = CountVectorizer(analyzer = stemmed_words)\n",
    "\n",
    "# Prepare X_train for the function\n",
    "X_train_stem_vectorized = stem_vectorizer.fit_transform(X_train)\n",
    "\n",
    "# Prepare X_test for the function\n",
    "X_test_stem_vectorized = stem_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the model you want to try\n",
    "model = LogisticRegression(max_iter=2500)\n",
    "\n",
    "# Call the function and store the row in the variable result\n",
    "result = evaluate_model(model, X_train_stem_vectorized, y_train, X_test_stem_vectorized, y_test, parameters=\"stopwords\", comments=\"Stemming_cv\")\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "new_row_df = pd.DataFrame([result])\n",
    "# don't forget to append the result to the results dataframe\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_df)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.539521</td>\n",
       "      <td>0.888785</td>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.447341</td>\n",
       "      <td>0.913705</td>\n",
       "      <td>[[96673  2670]\\n [ 6995  5662]]</td>\n",
       "      <td>0 minutes and 27.88 seconds</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>min_df=30</td>\n",
       "      <td>0.507491</td>\n",
       "      <td>0.916806</td>\n",
       "      <td>0.769095</td>\n",
       "      <td>0.378684</td>\n",
       "      <td>0.916937</td>\n",
       "      <td>[[97904  1439]\\n [ 7864  4793]]</td>\n",
       "      <td>0 minutes and 7.0 seconds</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td></td>\n",
       "      <td>0.519429</td>\n",
       "      <td>0.883760</td>\n",
       "      <td>0.688127</td>\n",
       "      <td>0.417160</td>\n",
       "      <td>0.912768</td>\n",
       "      <td>[[96950  2393]\\n [ 7377  5280]]</td>\n",
       "      <td>0 minutes and 44.53 seconds</td>\n",
       "      <td>Stemming+LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>stopwords</td>\n",
       "      <td>0.513327</td>\n",
       "      <td>0.882161</td>\n",
       "      <td>0.683941</td>\n",
       "      <td>0.410840</td>\n",
       "      <td>0.911964</td>\n",
       "      <td>[[96940  2403]\\n [ 7457  5200]]</td>\n",
       "      <td>0 minutes and 14.16 seconds</td>\n",
       "      <td>Stemming_cv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name Parameters  F1-Score   AUC-ROC  Precision    Recall  \\\n",
       "0  LogisticRegression     binary  0.539521  0.888785   0.679549  0.447341   \n",
       "1  LogisticRegression  min_df=30  0.507491  0.916806   0.769095  0.378684   \n",
       "2  LogisticRegression             0.519429  0.883760   0.688127  0.417160   \n",
       "3  LogisticRegression  stopwords  0.513327  0.882161   0.683941  0.410840   \n",
       "\n",
       "   Accuracy                 Confusion Matrix                Training Time  \\\n",
       "0  0.913705  [[96673  2670]\\n [ 6995  5662]]  0 minutes and 27.88 seconds   \n",
       "1  0.916937  [[97904  1439]\\n [ 7864  4793]]    0 minutes and 7.0 seconds   \n",
       "2  0.912768  [[96950  2393]\\n [ 7377  5280]]  0 minutes and 44.53 seconds   \n",
       "3  0.911964  [[96940  2403]\\n [ 7457  5200]]  0 minutes and 14.16 seconds   \n",
       "\n",
       "                      Comments  \n",
       "0                     Baseline  \n",
       "1              TfidfVectorizer  \n",
       "2  Stemming+LogisticRegression  \n",
       "3                  Stemming_cv  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialization\n",
    "WNlemma = nltk.WordNetLemmatizer()\n",
    "cv_analyzer = CountVectorizer().build_analyzer()\n",
    "\n",
    "def lemmatize_word(doc):\n",
    "    ''' \n",
    "    In this function the text is first passed through the build_analyzer() and then each word in the text is stemmed to its base form\n",
    "    '''\n",
    "    return (WNlemma.lemmatize(t) for t in cv_analyzer(doc))\n",
    "\n",
    "# define CountVectorizer with Lemmatization function \n",
    "lemm_vectorizer = CountVectorizer(analyzer = lemmatize_word)\n",
    "\n",
    "# Prepare X_train for the function\n",
    "X_train_lemm_vectorized = lemm_vectorizer.fit_transform(X_train)\n",
    "# Prepare X_test for the function\n",
    "X_test_lemm_vectorized  = lemm_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize the model you want to try\n",
    "model = LogisticRegression(max_iter=2500)\n",
    "\n",
    "# Call the function and store the row in the variable result\n",
    "result = evaluate_model(model, X_train_lemm_vectorized, y_train, X_test_lemm_vectorized, y_test, parameters=\"\", comments=\"lemmatization_cv\")\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "new_row_df = pd.DataFrame([result])\n",
    "# don't forget to append the result to the results dataframe\n",
    "results_df = pd.concat([results_df, pd.DataFrame(new_row_df)], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>binary</td>\n",
       "      <td>0.539521</td>\n",
       "      <td>0.888785</td>\n",
       "      <td>0.679549</td>\n",
       "      <td>0.447341</td>\n",
       "      <td>0.913705</td>\n",
       "      <td>[[96673  2670]\\n [ 6995  5662]]</td>\n",
       "      <td>0 minutes and 27.88 seconds</td>\n",
       "      <td>Baseline</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>min_df=30</td>\n",
       "      <td>0.507491</td>\n",
       "      <td>0.916806</td>\n",
       "      <td>0.769095</td>\n",
       "      <td>0.378684</td>\n",
       "      <td>0.916937</td>\n",
       "      <td>[[97904  1439]\\n [ 7864  4793]]</td>\n",
       "      <td>0 minutes and 7.0 seconds</td>\n",
       "      <td>TfidfVectorizer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td></td>\n",
       "      <td>0.519429</td>\n",
       "      <td>0.883760</td>\n",
       "      <td>0.688127</td>\n",
       "      <td>0.417160</td>\n",
       "      <td>0.912768</td>\n",
       "      <td>[[96950  2393]\\n [ 7377  5280]]</td>\n",
       "      <td>0 minutes and 44.53 seconds</td>\n",
       "      <td>Stemming+LogisticRegression</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>stopwords</td>\n",
       "      <td>0.513327</td>\n",
       "      <td>0.882161</td>\n",
       "      <td>0.683941</td>\n",
       "      <td>0.410840</td>\n",
       "      <td>0.911964</td>\n",
       "      <td>[[96940  2403]\\n [ 7457  5200]]</td>\n",
       "      <td>0 minutes and 14.16 seconds</td>\n",
       "      <td>Stemming_cv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td></td>\n",
       "      <td>0.531599</td>\n",
       "      <td>0.883216</td>\n",
       "      <td>0.685070</td>\n",
       "      <td>0.434305</td>\n",
       "      <td>0.913509</td>\n",
       "      <td>[[96816  2527]\\n [ 7160  5497]]</td>\n",
       "      <td>0 minutes and 48.44 seconds</td>\n",
       "      <td>lemmatization_cv</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name Parameters  F1-Score   AUC-ROC  Precision    Recall  \\\n",
       "0  LogisticRegression     binary  0.539521  0.888785   0.679549  0.447341   \n",
       "1  LogisticRegression  min_df=30  0.507491  0.916806   0.769095  0.378684   \n",
       "2  LogisticRegression             0.519429  0.883760   0.688127  0.417160   \n",
       "3  LogisticRegression  stopwords  0.513327  0.882161   0.683941  0.410840   \n",
       "4  LogisticRegression             0.531599  0.883216   0.685070  0.434305   \n",
       "\n",
       "   Accuracy                 Confusion Matrix                Training Time  \\\n",
       "0  0.913705  [[96673  2670]\\n [ 6995  5662]]  0 minutes and 27.88 seconds   \n",
       "1  0.916937  [[97904  1439]\\n [ 7864  4793]]    0 minutes and 7.0 seconds   \n",
       "2  0.912768  [[96950  2393]\\n [ 7377  5280]]  0 minutes and 44.53 seconds   \n",
       "3  0.911964  [[96940  2403]\\n [ 7457  5200]]  0 minutes and 14.16 seconds   \n",
       "4  0.913509  [[96816  2527]\\n [ 7160  5497]]  0 minutes and 48.44 seconds   \n",
       "\n",
       "                      Comments  \n",
       "0                     Baseline  \n",
       "1              TfidfVectorizer  \n",
       "2  Stemming+LogisticRegression  \n",
       "3                  Stemming_cv  \n",
       "4             lemmatization_cv  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word Vectors - Spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This initialize a pre-trained model (the small version) that uses Neural Networks to build word vectors\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "# convert words into vectors\n",
    "docs = [nlp(text) for text in X_train]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "maybe give a try to the library gensim https://www.youtube.com/watch?v=Q2NtCcqmIww&t=0s&ab_channel=codebasics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
