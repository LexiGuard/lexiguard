{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling LSTM, GRADIENT BOOSTING, FAST TEXT + RFC, FAST TEXT + LSTM\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImportS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "import spacy\n",
    "import ast\n",
    "import joblib\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from ast import literal_eval\n",
    "\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, precision_score, recall_score, confusion_matrix\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this initialize tqdm which is useful to show a progress bar when applying operations in a pandas df\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Extract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/undersampled_data_60_40.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text', 'toxic', 'stopwords_punct_lemma', 'vector_spacy',\n",
       "       'pos_tags', 'pos_tags_str'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop NaNs from df['stopwords_punct_lemma']\n",
    "df.dropna(subset=['stopwords_punct_lemma'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function to Calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize dataframe that will include the results\n",
    "results_df = pd.DataFrame()\n",
    "\n",
    "def evaluate_model(model, X_train,y_train,X_test,y_test, model_name=\"\", parameters='', comments=''):\n",
    "    start_time = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    duration = time.time() - start_time\n",
    "    duration_format = f\"{int(duration // 60)} minutes and {round(duration % 60, 2)} seconds\"\n",
    "    predicted_probs = model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    # Calculate metrics using probabilities\n",
    "    accuracy = accuracy_score(y_test, predictions)\n",
    "    f1 = f1_score(y_test, predictions)\n",
    "    roc_auc = roc_auc_score(y_test, predicted_probs)\n",
    "    precision = precision_score(y_test, predictions)\n",
    "    recall = recall_score(y_test, predictions)\n",
    "    conf_matrix = str(confusion_matrix(y_test, predictions))\n",
    "\n",
    "    # Create a dictionary including the results\n",
    "    results = {\n",
    "        'Name': model_name if model_name else model.__class__.__name__,\n",
    "        'Parameters': parameters,\n",
    "        'F1-Score': f1,\n",
    "        'AUC-ROC': roc_auc,\n",
    "        'Precision': precision,\n",
    "        'Recall': recall,\n",
    "        'Accuracy': accuracy,\n",
    "        'Confusion Matrix': conf_matrix,\n",
    "        'Training Time': duration_format,\n",
    "        'Comments': comments\n",
    "    }\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = df['stopwords_punct_lemma']\n",
    "y = df['toxic']\n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize TF-IDF Vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform on the training data\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           Name Parameters  F1-Score   AUC-ROC  Precision  \\\n",
      "0  Gradient Boosting Classifier     TF-IDF  0.659907  0.850829   0.914691   \n",
      "\n",
      "     Recall  Accuracy                 Confusion Matrix  \\\n",
      "0  0.516138  0.785904  [[41665  1396]\\n [14032 14968]]   \n",
      "\n",
      "                 Training Time Comments  \n",
      "0  2 minutes and 58.07 seconds           \n"
     ]
    }
   ],
   "source": [
    "# Transform the test data\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Initialize Gradient Boosting Classifier\n",
    "gb_classifier = GradientBoostingClassifier()\n",
    "\n",
    "# Evaluate Gradient Boosting Classifier using evaluate_model function\n",
    "results_gb = evaluate_model(gb_classifier, X_train_tfidf, y_train, X_test_tfidf, y_test, model_name=\"Gradient Boosting Classifier\", parameters=\"TF-IDF\")\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "results_df_gb = pd.DataFrame([results_gb])\n",
    "\n",
    "# Concatenate the new results DataFrame to the existing one\n",
    "results_df = pd.concat([results_df, results_df_gb], ignore_index=True)\n",
    "\n",
    "# Display the results\n",
    "print(results_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Parameters</th>\n",
       "      <th>F1-Score</th>\n",
       "      <th>AUC-ROC</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Confusion Matrix</th>\n",
       "      <th>Training Time</th>\n",
       "      <th>Comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>TF-IDF</td>\n",
       "      <td>0.659907</td>\n",
       "      <td>0.850829</td>\n",
       "      <td>0.914691</td>\n",
       "      <td>0.516138</td>\n",
       "      <td>0.785904</td>\n",
       "      <td>[[41665  1396]\\n [14032 14968]]</td>\n",
       "      <td>2 minutes and 58.07 seconds</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Name Parameters  F1-Score   AUC-ROC  Precision  \\\n",
       "0  Gradient Boosting Classifier     TF-IDF  0.659907  0.850829   0.914691   \n",
       "\n",
       "     Recall  Accuracy                 Confusion Matrix  \\\n",
       "0  0.516138  0.785904  [[41665  1396]\\n [14032 14968]]   \n",
       "\n",
       "                 Training Time Comments  \n",
       "0  2 minutes and 58.07 seconds           "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['comment_text'].values\n",
    "y = df['toxic'].values \n",
    "\n",
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Tokenize and convert text to sequences\n",
    "max_words = 10000  # Set the maximum number of words to consider\n",
    "max_len = 100  # Set the maximum length of each sequence\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer to a file\n",
    "tokenizer_file_path = 'data/tokenizer.pkl'\n",
    "with open(tokenizer_file_path, 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len)\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9021/9021 [==============================] - 247s 27ms/step - loss: 0.3341 - accuracy: 0.8596 - val_loss: 0.3001 - val_accuracy: 0.8755\n",
      "Epoch 2/5\n",
      "9021/9021 [==============================] - 239s 26ms/step - loss: 0.2868 - accuracy: 0.8808 - val_loss: 0.2987 - val_accuracy: 0.8756\n",
      "Epoch 3/5\n",
      "9021/9021 [==============================] - 248s 27ms/step - loss: 0.2627 - accuracy: 0.8915 - val_loss: 0.3014 - val_accuracy: 0.8744\n",
      "Epoch 4/5\n",
      "9021/9021 [==============================] - 243s 27ms/step - loss: 0.2357 - accuracy: 0.9026 - val_loss: 0.3127 - val_accuracy: 0.8720\n",
      "Epoch 5/5\n",
      "9021/9021 [==============================] - 228s 25ms/step - loss: 0.2035 - accuracy: 0.9166 - val_loss: 0.3454 - val_accuracy: 0.8664\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x45bf0e610>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_data=(X_test_padded, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open('model5.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save the model weights\n",
    "model.save_weights('model_weights5.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "with open('lstm_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2256/2256 [==============================] - 15s 6ms/step\n",
      "2256/2256 [==============================] - 14s 6ms/step\n",
      "Accuracy: 0.8389152936937936\n",
      "Precision: 0.8017638036809815\n",
      "Recall: 0.7948097722796227\n",
      "F1 Score: 0.7982716435004424\n",
      "AUC-ROC: 0.9027370638487501\n",
      "Confusion Matrix:\n",
      "[[37541  5687]\n",
      " [ 5938 23001]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "y_pred = (model.predict(X_test_padded) > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict(X_test_padded))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"AUC-ROC: {roc_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FAST Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df = pd.read_csv('data/undersampled_data_60_40_ft.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'comment_text', 'toxic', 'stopwords_punct_lemma',\n",
       "       'toxic_label_ft', 'toxic_label_comment_text', 'vector_fast_text'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [-0.0577833019, 0.0458838157, -0.0487854704, -...\n",
       "1    [-0.0385174714, 0.0294841994, -0.0353648514, -...\n",
       "2    [0.08621803, -0.06944817, 0.08360571, 0.003052...\n",
       "3    [-0.02172438, 0.01810819, -0.02264511, -0.0008...\n",
       "4    [-0.04083619, 0.03226621, -0.03952266, -0.0020...\n",
       "Name: new_ft, dtype: object"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ft_df['new_ft'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_vect = ft_df['vector_fast_text'].str.strip('[]').str.split(expand=True)\n",
    "corpus_vect = corpus_vect.astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "ft_df['new_ft'] = corpus_vect.values.tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RFC + fast_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9696090811950986\n"
     ]
    }
   ],
   "source": [
    "X = np.array(ft_df['new_ft'].tolist())\n",
    "y = ft_df['toxic']\n",
    "\n",
    "# Splitting the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Flatten X_train and X_test\n",
    "X_train_flatten = X_train.reshape(X_train.shape[0], -1)\n",
    "X_test_flatten = X_test.reshape(X_test.shape[0], -1)\n",
    "\n",
    "# Initialize RandomForestClassifier\n",
    "rfc = RandomForestClassifier()\n",
    "\n",
    "# Fit the model\n",
    "rfc.fit(X_train_flatten, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rfc.predict(X_test_flatten)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9696090811950986\n",
      "Precision: 0.9666179337231969\n",
      "Recall: 0.957551724137931\n",
      "F1 Score: 0.9620634700665189\n",
      "AUC-ROC: 0.9888729088406262\n",
      "Confusion Matrix:\n",
      "[[42102   959]\n",
      " [ 1231 27769]]\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "# Calculate precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "# Calculate recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "# Calculate F1-score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f\"F1 Score: {f1}\")\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "auc_roc = roc_auc_score(y_test, rfc.predict_proba(X_test_flatten)[:, 1])\n",
    "print(f\"AUC-ROC: {auc_roc}\")\n",
    "\n",
    "# Calculate confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM + fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(ft_df['new_ft'].tolist())\n",
    "y = ft_df['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_words = 10000  # Set the maximum number of words to consider\n",
    "max_len = 100  # Set the maximum length of each sequence\n",
    "\n",
    "X_padded = pad_sequences(X, maxlen=max_len) \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_padded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Define the LSTM model\n",
    "model = Sequential()\n",
    "X_train_reshaped = X_train.reshape(X_train.shape[0], X_train.shape[1], 1)\n",
    "\n",
    "model.add(LSTM(units=64, input_shape=(X_train.shape[1], 1))) \n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9008/9008 [==============================] - 179s 20ms/step - loss: 0.6713 - accuracy: 0.6022 - val_loss: 0.6714 - val_accuracy: 0.6005\n",
      "Epoch 2/5\n",
      "9008/9008 [==============================] - 172s 19ms/step - loss: 0.6705 - accuracy: 0.6028 - val_loss: 0.6715 - val_accuracy: 0.6005\n",
      "Epoch 3/5\n",
      "9008/9008 [==============================] - 173s 19ms/step - loss: 0.6705 - accuracy: 0.6028 - val_loss: 0.6714 - val_accuracy: 0.6005\n",
      "Epoch 4/5\n",
      "9008/9008 [==============================] - 174s 19ms/step - loss: 0.6720 - accuracy: 0.6018 - val_loss: 0.6715 - val_accuracy: 0.6004\n",
      "Epoch 5/5\n",
      "9008/9008 [==============================] - 178s 20ms/step - loss: 0.6708 - accuracy: 0.6027 - val_loss: 0.6714 - val_accuracy: 0.6004\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x5751eba10>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model in .h5 file\n",
    "model.save('lstm_model_ft.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2252/2252 [==============================] - 14s 6ms/step\n",
      "2252/2252 [==============================] - 14s 6ms/step\n",
      "Accuracy: 0.6004079876771069\n",
      "Precision: 0.9723502304147466\n",
      "Recall: 0.0072758620689655175\n",
      "F1 Score: 0.014443645822637506\n",
      "AUC-ROC: 0.5034765537100937\n",
      "Confusion Matrix:\n",
      "[[43055     6]\n",
      " [28789   211]]\n"
     ]
    }
   ],
   "source": [
    "y_pred = (model.predict(X_test) > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict(X_test))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"AUC-ROC: {roc_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM on cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = pd.read_csv('data/data_usampl_60_40_comments_cleaned_preproc.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment_clean</th>\n",
       "      <th>comment_clean_preproc</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Well, what are the chances he will turn out to...</td>\n",
       "      <td>chance turn active proponent slavery</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The moment of critical mass is approaching whe...</td>\n",
       "      <td>moment critical mass approach deed Gupta Co li...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"Hey listen to me,\" he said. \"I'm not going to...</td>\n",
       "      <td>hey listen say go crap prove reporter say uh a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>We are already owed $_number_ M plus interest(...</td>\n",
       "      <td>owe $ number M plus interest($_number_Billion ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>There is a reason there are no teeth to the la...</td>\n",
       "      <td>reason tooth law unlawful law way force free e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       comment_clean  \\\n",
       "0  Well, what are the chances he will turn out to...   \n",
       "1  The moment of critical mass is approaching whe...   \n",
       "2  \"Hey listen to me,\" he said. \"I'm not going to...   \n",
       "3  We are already owed $_number_ M plus interest(...   \n",
       "4  There is a reason there are no teeth to the la...   \n",
       "\n",
       "                               comment_clean_preproc  toxic  \n",
       "0               chance turn active proponent slavery      0  \n",
       "1  moment critical mass approach deed Gupta Co li...      0  \n",
       "2  hey listen say go crap prove reporter say uh a...      1  \n",
       "3  owe $ number M plus interest($_number_Billion ...      0  \n",
       "4  reason tooth law unlawful law way force free e...      0  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['comment_clean'] = df_clean['comment_clean'].astype(str)\n",
    "df_clean['comment_clean_preproc'] = df_clean['comment_clean_preproc'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_clean['comment_clean_preproc'].values\n",
    "y = df_clean['toxic'].values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "# Tokenize and convert text to sequences\n",
    "max_words = 10000  # Set the maximum number of words to consider\n",
    "max_len = 100  # Set the maximum length of each sequence\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the tokenizer to a file\n",
    "tokenizer_file_path = 'data/tokenizer_clean.pkl'\n",
    "with open(tokenizer_file_path, 'wb') as handle:\n",
    "    pickle.dump(tokenizer, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pad sequences to a fixed length\n",
    "X_train_padded = pad_sequences(X_train_seq, maxlen=max_len)\n",
    "X_test_padded = pad_sequences(X_test_seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(Embedding(input_dim=max_words, output_dim=128, input_length=max_len))\n",
    "model.add(LSTM(units=64))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-13 15:41:11.776438: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9021/9021 [==============================] - 236s 26ms/step - loss: 0.3055 - accuracy: 0.8713 - val_loss: 0.2822 - val_accuracy: 0.8827\n",
      "Epoch 2/5\n",
      "9021/9021 [==============================] - 231s 26ms/step - loss: 0.2672 - accuracy: 0.8879 - val_loss: 0.2812 - val_accuracy: 0.8821\n",
      "Epoch 3/5\n",
      "9021/9021 [==============================] - 235s 26ms/step - loss: 0.2406 - accuracy: 0.9000 - val_loss: 0.2916 - val_accuracy: 0.8809\n",
      "Epoch 4/5\n",
      "9021/9021 [==============================] - 226s 25ms/step - loss: 0.2099 - accuracy: 0.9134 - val_loss: 0.3164 - val_accuracy: 0.8736\n",
      "Epoch 5/5\n",
      "9021/9021 [==============================] - 232s 26ms/step - loss: 0.1774 - accuracy: 0.9278 - val_loss: 0.3414 - val_accuracy: 0.8666\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2ba90d090>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train_padded, y_train, epochs=5, batch_size=32, validation_data=(X_test_padded, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model architecture as JSON\n",
    "model_json = model.to_json()\n",
    "with open('data/model_clean.json', 'w') as json_file:\n",
    "    json_file.write(model_json)\n",
    "\n",
    "# Save the model weights\n",
    "model.save_weights('data/model_weights_clean.h5')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2256/2256 [==============================] - 15s 7ms/step\n",
      "2256/2256 [==============================] - 15s 7ms/step\n",
      "Accuracy: 0.8665595078082781\n",
      "Precision: 0.8288205442593917\n",
      "Recall: 0.8409067348560766\n",
      "F1 Score: 0.834819897084048\n",
      "AUC-ROC: 0.9346512256536599\n",
      "Confusion Matrix:\n",
      "[[38202  5026]\n",
      " [ 4604 24335]]\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "y_pred = (model.predict(X_test_padded) > 0.5).astype(int)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "roc_auc = roc_auc_score(y_test, model.predict(X_test_padded))\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")\n",
    "print(f\"F1 Score: {f1}\")\n",
    "print(f\"AUC-ROC: {roc_auc}\")\n",
    "print(f\"Confusion Matrix:\\n{conf_matrix}\")\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7ee5ce8695951d3743acb1574d7cbc518a435066b16546d59d44a9748127e061"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
